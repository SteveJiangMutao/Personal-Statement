import streamlit as st
import google.generativeai as genai
from PIL import Image
import docx
import PyPDF2
import io
import os
import time
import random
from datetime import datetime

# ==========================================
# 0. è‡ªåŠ¨ç‰ˆæœ¬å·ç”Ÿæˆé€»è¾‘
# ==========================================
def get_app_version():
    try:
        timestamp = os.path.getmtime(__file__)
        dt = datetime.fromtimestamp(timestamp)
        # æ ¼å¼ï¼šv13.19.æœˆæ—¥.æ—¶åˆ†
        build_ver = dt.strftime('%m%d.%H%M')
        return f"v13.19.{build_ver}", dt.strftime('%Y-%m-%d %H:%M:%S')
    except Exception:
        return "v13.19.Dev", "Unknown"

current_version, last_updated_time = get_app_version()

# ==========================================
# 1. é¡µé¢åŸºç¡€é…ç½® & ç»ˆæ CSS å¯¹é½
# ==========================================
st.set_page_config(page_title=f"ç•™å­¦æ–‡ä¹¦å·¥å…· {current_version}", layout="wide")

# --- CSS Hack: å¼ºåˆ¶åº•éƒ¨è¾¹æ¡†å¯¹é½ ---
st.markdown("""
<style>
    /* 1. æ°´å¹³å®¹å™¨ï¼šå¼ºåˆ¶å­å…ƒç´ é«˜åº¦æ‹‰ä¼¸ */
    div[data-testid="stHorizontalBlock"] {
        align-items: stretch;
        height: auto;
    }

    /* 2. åˆ—å®¹å™¨ï¼šè®¾ç½®ä¸º Flex å¸ƒå±€ï¼Œå¹¶å¼ºåˆ¶é«˜åº¦ 100% */
    div[data-testid="column"] {
        display: flex;
        flex-direction: column;
        height: 100%;
    }

    /* 3. å¡ç‰‡å®¹å™¨ (å¸¦è¾¹æ¡†çš„)ï¼šå¼ºåˆ¶å æ»¡å‰©ä½™ç©ºé—´ï¼Œç¡®ä¿é«˜åº¦ä¸€è‡´ */
    div[data-testid="stVerticalBlockBorderWrapper"] {
        flex-grow: 1;
        display: flex;
        flex-direction: column;
        height: 100%;
        min-height: 100%; /* æ ¸å¿ƒï¼šå¼ºåˆ¶æœ€å°é«˜åº¦ä¹Ÿå¡«æ»¡ */
    }
    
    /* 4. å†…éƒ¨å†…å®¹å®¹å™¨ï¼šå…è®¸å†…å®¹è‡ªç„¶å¡«å…… */
    div[data-testid="stVerticalBlockBorderWrapper"] > div {
        flex-grow: 1;
    }

    /* 5. ç´§å‡‘åŒ– Label é—´è· */
    .stMarkdown p {
        margin-bottom: 0px;
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ– Session State
if 'generated_sections' not in st.session_state:
    st.session_state['generated_sections'] = {}
if 'motivation_trends' not in st.session_state:
    st.session_state['motivation_trends'] = ""
if 'translated_sections' not in st.session_state:
    st.session_state['translated_sections'] = {}
if 'chat_histories' not in st.session_state:
    st.session_state['chat_histories'] = {} 

st.title(f"ç•™å­¦æ–‡ä¹¦è¾…åŠ©å†™ä½œå·¥å…· {current_version}")
st.markdown("---")

# ==========================================
# 2. æ ¸å¿ƒæ–‡æ¡ˆåº“ (å¹½é»˜åŠ è½½ + æƒ…ç»ªä»·å€¼)
# ==========================================

# --- A. å¹½é»˜åŠ è½½æ–‡æ¡ˆåº“ ---
FUNNY_LOADING_MESSAGES = [
    "â˜•ï¸ æ­£åœ¨ç…®å’–å•¡ï¼Œé¡ºä¾¿æ€è€ƒä¸€ä¸‹äººç”Ÿ...",
    "ğŸ§  æ­£åœ¨å’Œ Google æ€»éƒ¨çš„æœåŠ¡å™¨è¿›è¡Œè„‘ç”µæ³¢å¯¹æ¥...",
    "ğŸš€ æ­£åœ¨ä»¥æ­¤ç”Ÿæœ€å¿«çš„é€Ÿåº¦ç¿»é˜…æ•´ä¸ªäº’è”ç½‘...",
    "ğŸ¢ åˆ«æ€¥ï¼ŒAI ä¹Ÿæ˜¯éœ€è¦å–˜å£æ°”çš„...",
    "ğŸ”¥ ä¸ºäº†è¿™ä¸ªé—®é¢˜ï¼Œæ˜¾å¡æ­£åœ¨å¾®å¾®å‘çƒ«...",
    "ğŸ§™â€â™‚ï¸ æ­£åœ¨å¬å”¤æ•°æ®é­”æ³•ï¼Œè¯·å‹¿æ‰“æ‰°...",
    "ğŸ§ æ­£åœ¨å‡è£…å¾ˆæ·±æ²‰åœ°æ€è€ƒ...",
    "ğŸ’¾ æ­£åœ¨ä»èµ›åšç©ºé—´çš„è§’è½é‡Œæ‰“ææ•°æ®...",
    "âœ¨ çµæ„Ÿæ­£åœ¨åŠ è½½ä¸­ï¼Œè¿›åº¦ 99%...",
    "ğŸ¤– æ­£åœ¨å­¦ä¹ å¦‚ä½•åƒäººç±»ä¸€æ ·è¯´è¯...",
    "ğŸ“š æ­£åœ¨å¿«é€Ÿé˜…è¯» 1000 æœ¬ç›¸å…³ä¹¦ç±...",
    "ğŸª æ­£åœ¨å‘å¤–æ˜Ÿæ–‡æ˜å‘é€æ±‚åŠ©ä¿¡å·...",
    "ğŸ• æ­£åœ¨åƒä¸€å£è™šæ‹ŸæŠ«è¨è¡¥å……èƒ½é‡...",
    "ğŸ» æ­£åœ¨ä¸ºæ‚¨æ¼”å¥ä¸€é¦–æ•°æ®äº¤å“æ›²...",
    "ğŸƒâ€â™‚ï¸ æ­£åœ¨æ•°æ®çš„æµ·æ´‹é‡Œç‹‚å¥”...",
    "ğŸ§© æ­£åœ¨æ‹¼å‡‘é€»è¾‘çš„ç¢ç‰‡...",
    "ğŸ”‹ æ­£åœ¨ç»™ç¥ç»å…ƒå……ç”µ...",
    "ğŸ“¡ æ­£åœ¨æ ¡å‡†å«æ˜Ÿä¿¡å·...",
    "ğŸ§¹ æ­£åœ¨æ¸…ç†æ€ç»´é‡Œçš„æ‚è‰...",
    "ğŸ² æ­£åœ¨æ·éª°å­å†³å®šç”¨å“ªä¸ªè¯ï¼ˆå¼€ç©ç¬‘çš„ï¼‰..."
]

# --- B. æƒ…ç»ªä»·å€¼æ–‡æ¡ˆåº“ (Daily Vibe) ---
DAILY_VIBES = [
    "ğŸŒŸ Your story matters. \nä½ çš„æ•…äº‹å€¼å¾—è¢«ä¸–ç•Œå¬è§ã€‚",
    "â˜•ï¸ Coffee in hand, confidence in mind. \næ‰‹ä¸­æœ‰å’–å•¡ï¼Œå¿ƒä¸­æœ‰æ¢¦æƒ³ã€‚",
    "ğŸš€ One step closer to your dream school. \næ¯ä¸€ä¸ªå•è¯ï¼Œéƒ½æ˜¯é€šå¾€æ¢¦æ ¡çš„é˜¶æ¢¯ã€‚",
    "ğŸŒˆ Trust the process. \nç›¸ä¿¡è¿‡ç¨‹ï¼Œç»“æœè‡ªä¼šå‘ç”Ÿã€‚",
    "âœ¨ Small steps, big dreams. \nä»Šå¤©çš„åŠªåŠ›ï¼Œæ˜¯æœªæ¥çš„ä¼ç¬”ã€‚",
    "ğŸ“ You are capable of amazing things. \nä½ æ¯”æƒ³è±¡ä¸­æ›´å¼ºå¤§ã€‚",
    "ğŸ’¡ Shine bright. \nå»å‘å…‰å§ï¼Œä¸ä»…æ˜¯ä¸ºäº†è¢«çœ‹è§ã€‚",
    "ğŸ›¤ï¸ The journey is the reward. \nç”³è¯·å­£æœ¬èº«å°±æ˜¯ä¸€åœºèœ•å˜ã€‚",
    "ğŸ’ª Keep going, you got this. \nåšæŒä½ï¼ŒOffer æ­£åœ¨è·¯ä¸Šã€‚",
    "ğŸŒ The world is waiting for you. \nä¸–ç•Œå¾ˆå¤§ï¼Œç­‰ä½ æ¢ç´¢ã€‚",
    "âœ’ï¸ Write your own future. \næç¬”ï¼Œå³æ˜¯æœªæ¥ã€‚",
    "ğŸ¦ Be bold, be you. \nå‹‡æ•¢åšè‡ªå·±ï¼Œè¿™æœ€åŠ¨äººã€‚"
]

def get_random_loading_msg():
    return random.choice(FUNNY_LOADING_MESSAGES)

def stream_vibe_text():
    """ç”Ÿæˆå™¨å‡½æ•°ï¼Œç”¨äºäº§ç”Ÿæ‰“å­—æœºæ•ˆæœ"""
    quote = random.choice(DAILY_VIBES)
    for word in quote.split(): 
        yield word + " "
        time.sleep(0.05) # æ§åˆ¶æ‰“å­—é€Ÿåº¦

# ==========================================
# 3. ç³»ç»Ÿè®¾ç½® (ä¾§è¾¹æ  - å«æƒ…ç»ªä»·å€¼æ¨¡å—)
# ==========================================
with st.sidebar:
    # --- ğŸŒŸ æƒ…ç»ªä»·å€¼æ¨¡å— (Daily Vibe) ---
    st.markdown("### âœ¨ Daily Vibe")
    with st.container(border=True):
        st.write_stream(stream_vibe_text)
    
    st.markdown("---")
    
    st.header("ç³»ç»Ÿè®¾ç½®")
    
    api_key = st.text_input("ğŸ”‘ è¯·è¾“å…¥ Google API Key", type="password", help="è¯·åœ¨ Google AI Studio ç”³è¯· Key")
    
    if not api_key:
        st.warning("âš ï¸ è¯·è¾“å…¥ Key")
    else:
        st.success("âœ… Key å·²å°±ç»ª")
    
    model_name = st.selectbox("é€‰æ‹©æ¨¡å‹", ["gemini-3-pro-preview"], index=0)
    
    st.markdown("---")
    st.markdown("### å…³äº")
    st.info(f"**å½“å‰ç‰ˆæœ¬:** {current_version}")
    st.caption(f"**æœ€åæ›´æ–°:** {last_updated_time}")
    st.caption("**Update:** æ–°å¢è‹±å¼/ç¾å¼æ‹¼å†™åˆ‡æ¢åŠŸèƒ½")

# ==========================================
# 4. æ ¸å¿ƒå‡½æ•°
# ==========================================
def read_word_file(file):
    try:
        doc = docx.Document(file)
        full_text = []
        for para in doc.paragraphs:
            full_text.append(para.text)
        return '\n'.join(full_text)
    except Exception as e:
        return f"Error reading Word file: {e}"

def read_pdf_text(file):
    try:
        pdf_reader = PyPDF2.PdfReader(file)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"
        return text
    except Exception as e:
        return f"Error reading PDF file: {e}"

def get_gemini_response(prompt, media_content=None, text_context=None):
    if not api_key:
        return "Error: è¯·å…ˆåœ¨å·¦ä¾§ä¾§è¾¹æ è¾“å…¥ API Key"
        
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel(model_name)
    
    content = []
    content.append(prompt)
    
    if text_context:
        content.append(f"\nã€å‚è€ƒæ–‡æ¡£/èƒŒæ™¯ä¿¡æ¯ (ç®€å†æˆ–ç´ æè¡¨)ã€‘:\n{text_context}")
    
    if media_content:
        if isinstance(media_content, list):
            content.extend(media_content)
        else:
            content.append(media_content)
        
    try:
        response = model.generate_content(content)
        return response.text
    except Exception as e:
        return f"Error: {str(e)}"

# ==========================================
# 5. ç•Œé¢ï¼šä¿¡æ¯é‡‡é›† (UI ç»ˆæå¯¹é½ç‰ˆ)
# ==========================================
st.header("1. ä¿¡æ¯é‡‡é›†ä¸ç´ æä¸Šä¼ ")

col_student, col_counselor, col_target = st.columns(3)

# --- ç¬¬ä¸€æ ï¼šå­¦ç”Ÿæä¾›ä¿¡æ¯ ---
with col_student:
    with st.container(border=True):
        st.markdown("### å­¦ç”Ÿæä¾›ä¿¡æ¯")
        st.caption("ä¸Šä¼ ç®€å†ã€ç´ æè¡¨ä¸æˆç»©å•")
        
        uploaded_material = st.file_uploader("ğŸ“„ æ–‡ä¹¦ç´ æ/ç®€å† (Word/PDF)", type=['docx', 'pdf'])
        uploaded_transcript = st.file_uploader("ğŸ“ æˆç»©å• (æˆªå›¾/PDF)", type=['png', 'jpg', 'jpeg', 'pdf'])

# --- ç¬¬äºŒæ ï¼šé¡¾é—®æŒ‡å¯¼æ„è§ ---
with col_counselor:
    with st.container(border=True):
        st.markdown("### é¡¾é—®æŒ‡å¯¼æ„è§")
        st.caption("è®¾å®šæ–‡ä¹¦çš„æ•´ä½“ç­–ç•¥ä¸è°ƒæ€§")
        
        counselor_strategy = st.text_area(
            "ğŸ’¡ å†™ä½œç­–ç•¥/äººè®¾å¼ºè°ƒ", 
            height=280, 
            placeholder="ä¾‹å¦‚ï¼š\n1. å¼ºè°ƒé‡åŒ–èƒŒæ™¯\n2. è§£é‡ŠGPAåŠ£åŠ¿\n3. çªå‡ºæŸæ®µå®ä¹ çš„é¢†å¯¼åŠ›..."
        )

# --- ç¬¬ä¸‰æ ï¼šç›®æ ‡ä¸“ä¸šä¿¡æ¯ ---
with col_target:
    with st.container(border=True):
        st.markdown("### ç›®æ ‡ä¸“ä¸šä¿¡æ¯")
        st.caption("è¾“å…¥ç›®æ ‡å­¦æ ¡ä¸è¯¾ç¨‹è®¾ç½®")
        
        target_school_name = st.text_input("ğŸ›ï¸ ç›®æ ‡å­¦æ ¡ & ä¸“ä¸š", placeholder="ä¾‹å¦‚ï¼šUCL - MSc Business Analytics")
        
        st.markdown("**ğŸ“– è¯¾ç¨‹è®¾ç½® (Curriculum)**") 
        
        tab_text, tab_img = st.tabs(["æ–‡æœ¬ç²˜è´´", "å›¾ç‰‡ä¸Šä¼ "])
        
        with tab_text:
            target_curriculum_text = st.text_area("ç²˜è´´è¯¾ç¨‹åˆ—è¡¨", height=140, placeholder="Core Modules: ...", label_visibility="collapsed")
        
        with tab_img:
            uploaded_curriculum_images = st.file_uploader("ä¸Šä¼ è¯¾ç¨‹æˆªå›¾", type=['png', 'jpg', 'jpeg'], accept_multiple_files=True, label_visibility="collapsed")

# è¯»å–ç´ ææ–‡æœ¬
student_background_text = ""
if uploaded_material:
    if uploaded_material.name.endswith('.docx'):
        student_background_text = read_word_file(uploaded_material)
    elif uploaded_material.name.endswith('.pdf'):
        student_background_text = read_pdf_text(uploaded_material)

# ==========================================
# 6. ç•Œé¢ï¼šå†™ä½œè®¾å®š (æ–°å¢æ‹¼å†™é€‰é¡¹)
# ==========================================
st.markdown("---")
st.header("2. å†™ä½œè®¾å®š") # å·²é‡å‘½å

modules = {
    "Motivation": "ç”³è¯·åŠ¨æœº",
    "Academic": "æœ¬ç§‘å­¦ä¹ ç»å†",
    "Internship": "å®ä¹ /å·¥ä½œç»å†",
    "Why_School": "Why School",
    "Career_Goal": "èŒä¸šè§„åˆ’"
}

# ä½¿ç”¨åˆ—å¸ƒå±€æ¥æ”¾ç½® æ¨¡å—é€‰æ‹© å’Œ æ‹¼å†™é€‰æ‹©
col_modules, col_style = st.columns([3, 1])

with col_modules:
    selected_modules = st.multiselect("é€‰æ‹©æ¨¡å—ï¼š", list(modules.keys()), format_func=lambda x: modules[x], default=list(modules.keys()))

with col_style:
    # æ–°å¢ï¼šæ‹¼å†™é£æ ¼é€‰æ‹©
    spelling_preference = st.radio(
        "ğŸ”¤ æ‹¼å†™åå¥½ (Spelling)",
        ["ğŸ‡¬ğŸ‡§ è‹±å¼ (British)", "ğŸ‡ºğŸ‡¸ ç¾å¼ (American)"],
        help="ç¿»è¯‘æ—¶å°†ä¸¥æ ¼éµå¾ªæ‰€é€‰çš„æ‹¼å†™ä¹ æƒ¯ (å¦‚ colour vs color)"
    )

# ==========================================
# 7. æ ¸å¿ƒé€»è¾‘ï¼šç”Ÿæˆ Prompt
# ==========================================
st.markdown("---")
st.header("3. ä¸€é”®ç‚¹å‡»åˆ›ä½œ")

CLEAN_OUTPUT_RULES = """
ã€ğŸš¨ ç»å¯¹è¾“å‡ºè§„åˆ™ã€‘
1. åªè¾“å‡ºæ­£æ–‡å†…å®¹æœ¬èº«ã€‚
2. ä¸¥ç¦åŒ…å«å¼€åœºç™½ã€ç»“å°¾è¯­æˆ–ç»“æ„è¯´æ˜ã€‚
3. ä¸¥ç¦ä½¿ç”¨ Markdown æ ¼å¼ï¼ˆå¦‚åŠ ç²—ã€åˆ—è¡¨ç¬¦å·ã€æ ‡é¢˜ç¬¦å·ï¼‰ã€‚
4. è¾“å‡ºå¿…é¡»æ˜¯çº¯æ–‡æœ¬ã€‚
5. å¿…é¡»å†™æˆä¸€ä¸ªå®Œæ•´çš„ã€è¿è´¯çš„ä¸­æ–‡è‡ªç„¶æ®µã€‚
"""

# æ³¨æ„ï¼šè¿™é‡Œåªå®šä¹‰åŸºç¡€è§„åˆ™ï¼Œæ‹¼å†™è§„åˆ™ä¼šåœ¨ç‚¹å‡»ç¿»è¯‘æŒ‰é’®æ—¶åŠ¨æ€æ³¨å…¥
TRANSLATION_RULES_BASE = """
ã€Translation Taskã€‘
Translate the provided Chinese text into a professional, human-sounding Personal Statement paragraph.

ã€ğŸš¨ CRITICAL ANTI-AI STYLE GUIDEã€‘
1. **KILL THE "AI SENTENCE PATTERN"**: 
   - **ABSOLUTELY FORBIDDEN**: The pattern "I did X, **thereby/thus/enabling** me to do Y." 
   - **SOLUTION**: Split into two sentences or use active verbs.

2. **SEMICOLONS (;) FOR FLOW**:
   - **MANDATORY**: When a sentence is grammatically complete but the thought is not finished (and leads directly into the next point), use a **semicolon (;)** to connect them.
   - *Example*: "The model failed initially; this failure forced me to re-evaluate the parameters."

3. **ADVERB CONTROL (Nuanced)**:
   - **STRICTLY PROHIBITED**: Adverbs placed immediately before verbs or adjectives to intensify them (e.g., "deeply analyze", "perfectly align").
   - **ALLOWED**: "Robust" and "scalable" are permitted.

4. **VOCABULARY PURGE**: 
   - Avoid "delve into", "pivotal", "tapestry". Use precise, simple words.

ã€ğŸš« BANNED WORDS LIST (Strictly Prohibited)ã€‘
[Verbs]: delve into, uncover, reveal, recognize, master, refine, cultivate, address, bridge, spearhead, pioneer, align with, stems from, underscore, highlight
[Adjectives/Adverbs]: instrumental, pivotal, seamless, systematically, rigorously, profoundly, deeply, acutely, keenly, comprehensively, perfectly, meticulously
[Nouns]: paradigm, trajectory, aspirations, vision, landscape, tapestry, realm, foundation
[Connectors]: thereby, thus (when used with -ing), in turn
[Phrases]: "not only... but also", "Building on this", "rich tapestry", "testament to", "a wide array of"

ã€Formattingã€‘
1. Output as ONE single paragraph.
2. Output the ENTIRE text in **Bold**.
3. No Markdown headers.
"""

if st.button("å¼€å§‹ç”Ÿæˆåˆç¨¿", type="primary"):
    if not api_key:
        st.error("âŒ è¯·å…ˆåœ¨å·¦ä¾§ä¾§è¾¹æ è¾“å…¥æœ‰æ•ˆçš„ Google API Key")
        st.stop()

    has_curriculum = target_curriculum_text or uploaded_curriculum_images
    
    if not uploaded_material or not uploaded_transcript or not has_curriculum:
        st.error("è¯·ç¡®ä¿ï¼šæ–‡ä¹¦ç´ æ/ç®€å†ã€æˆç»©å•ã€ç›®æ ‡è¯¾ç¨‹ä¿¡æ¯ å‡å·²æä¾›ã€‚")
        st.stop()
    
    # å‡†å¤‡åª’ä½“
    transcript_content = []
    if uploaded_transcript.type == "application/pdf":
        transcript_content.append({
            "mime_type": "application/pdf",
            "data": uploaded_transcript.getvalue()
        })
    else:
        transcript_content.append(Image.open(uploaded_transcript))

    curriculum_imgs = []
    if uploaded_curriculum_images:
        for img_file in uploaded_curriculum_images:
            curriculum_imgs.append(Image.open(img_file))
    
    progress_bar = st.progress(0)
    total_steps = len(selected_modules)
    current_step = 0

    # --- Prompt å®šä¹‰ ---
    prompt_motivation = f"""
    ã€ä»»åŠ¡ã€‘æ’°å†™ Personal Statement çš„ "ç”³è¯·åŠ¨æœº" éƒ¨åˆ†ã€‚
    ã€æ­¥éª¤ 1ï¼šæ·±åº¦è°ƒç ”ã€‘
    è¯·å…ˆåˆ†æ {target_school_name} æ‰€åœ¨é¢†åŸŸçš„æœ€æ–°è¡Œä¸šçƒ­ç‚¹æˆ–å­¦æœ¯è¶‹åŠ¿ï¼ˆåˆ—å‡º 2-3 ä¸ªï¼‰ã€‚
    **å¿…é¡»æä¾›å…·ä½“ä¿¡æ¯æº**ï¼š
    - å…·ä½“çš„è®ºæ–‡æ ‡é¢˜ (Title & Year)
    - çŸ¥åå’¨è¯¢æœºæ„æŠ¥å‘Šåç§° (å¦‚ McKinsey, Deloitte, Gartner)
    - æƒå¨ç§‘æŠ€/å•†ä¸šæ–°é—»æº (å¦‚ TechCrunch, Bloomberg, Nature)
    - ç®€è¿°è¯¥è¶‹åŠ¿ä¸å­¦ç”ŸèƒŒæ™¯çš„å…³è”ã€‚
    ã€æ­¥éª¤ 2ï¼šæ’°å†™æ­£æ–‡ã€‘
    åŸºäºä¸Šè¿°è¶‹åŠ¿å’Œå­¦ç”Ÿç´ æï¼Œæ’°å†™ä¸€æ®µä¸­æ–‡ç”³è¯·åŠ¨æœºã€‚
    é€»è¾‘ï¼šå­¦ç”Ÿè¿‡å¾€ç»å† -> è§‚å¯Ÿåˆ°çš„è¡Œä¸šç—›ç‚¹/è¶‹åŠ¿ -> äº§ç”Ÿæ·±é€ éœ€æ±‚ã€‚
    ã€ğŸš¨ ä¸¥æ ¼è¾“å‡ºæ ¼å¼ã€‘
    è¯·ä¸¥æ ¼æŒ‰ç…§ä¸‹æ–¹åˆ†éš”ç¬¦è¾“å‡ºï¼Œä¸è¦åŒ…å«å…¶ä»–å†…å®¹ï¼š
    [TRENDS_START]
    (åœ¨æ­¤å¤„åˆ—å‡ºè°ƒç ”çš„è¶‹åŠ¿å’Œå…·ä½“æ¥æºé“¾æ¥/æ ‡é¢˜)
    [TRENDS_END]
    [DRAFT_START]
    (åœ¨æ­¤å¤„æ’°å†™æ­£æ–‡æ®µè½ï¼Œçº¯æ–‡æœ¬ï¼Œæ— Markdown)
    [DRAFT_END]
    """

    prompt_career = f"""
    ã€ä»»åŠ¡ã€‘æ’°å†™ "èŒä¸šè§„åˆ’" (Career Goals) éƒ¨åˆ†ã€‚
    ã€è¾“å…¥èƒŒæ™¯ã€‘
    - ç›®æ ‡ä¸“ä¸š: {target_school_name}
    - é¡¾é—®æ€è·¯: {counselor_strategy}
    ã€å†…å®¹è¦æ±‚ã€‘
    1. è§„åˆ’ç¡•å£«æ¯•ä¸šåçš„è·¯å¾„ï¼ˆåº”å±Šç”Ÿè§†è§’ï¼‰ã€‚
    2. **å¿…é¡»åŒ…å«**ï¼šå…·ä½“çš„å…¬å¸åå­—ã€å…·ä½“çš„èŒä½åç§°ã€‚
    3. å°†å·¥ä½œå†…å®¹å’Œæœªæ¥ç»§ç»­å­¦ä¹ æ–¹å‘èåˆåœ¨ä¸€æ®µè¯ä¸­ã€‚
    {CLEAN_OUTPUT_RULES}
    """

    prompt_academic = f"""
    ã€ä»»åŠ¡ã€‘æ’°å†™ "æœ¬ç§‘å­¦ä¹ ç»å†" (Academic Background) éƒ¨åˆ†ã€‚
    ã€è¾“å…¥èƒŒæ™¯ã€‘
    - ç›®æ ‡ä¸“ä¸š: {target_school_name}
    - æ ¸å¿ƒä¾æ® (æˆç»©å•): è§é™„å¸¦æ–‡ä»¶ (PDFæˆ–å›¾ç‰‡)
    - è¾…åŠ©å‚è€ƒ (å­¦ç”Ÿç´ æ/ç®€å†): è§é™„å¸¦æ–‡æœ¬
    ã€æ ¸å¿ƒåŸåˆ™ï¼šæ·±åº¦ > æ•°é‡ã€‘
    ä¸è¦ç½—åˆ—è¯¾ç¨‹åã€‚åªç²¾é€‰ **2-3 é—¨** ä¸ç›®æ ‡ä¸“ä¸šæœ€å¼ºç›¸å…³çš„æ ¸å¿ƒè¯¾ç¨‹è¿›è¡Œæ·±åº¦æå†™ã€‚
    ã€å†…å®¹è¦æ±‚ - å¿…é¡»åŒ…å«ç»†èŠ‚ã€‘
    1. **æ ¸å¿ƒæ¦‚å¿µæ¤å…¥**ï¼šåœ¨æè¿°æ¯é—¨è¯¾æ—¶ï¼Œå¿…é¡»æåŠè¯¥è¯¾ç¨‹å…·ä½“çš„**æ ¸å¿ƒæ¦‚å¿µã€æ¨¡å‹ã€ç®—æ³•æˆ–ç†è®ºåç§°**ã€‚
    2. **å­¦æœ¯çœŸå®æ„Ÿ**ï¼šç»“åˆå­¦ç”Ÿç´ æï¼Œç®€è¿°æ˜¯å¦‚ä½•ç†è§£æˆ–åº”ç”¨è¿™äº›æ¦‚å¿µçš„ã€‚
    3. **é€»è¾‘å‡å**ï¼šè¯´æ˜è¿™äº›å…·ä½“çš„çŸ¥è¯†ç‚¹å¦‚ä½•ä¸ºä½ æ”»è¯» {target_school_name} æ‰“ä¸‹äº†åšå®çš„å­¦æœ¯åŸºç¡€ã€‚
    4. **ç¦æ­¢**ï¼šç¦æ­¢å†™æˆè¯¾ç¨‹æ¸…å•ï¼ˆListï¼‰ï¼Œå¿…é¡»æ˜¯è¿è´¯çš„å­¦æœ¯åæ€å™è¿°ã€‚
    {CLEAN_OUTPUT_RULES}
    """

    prompt_whyschool = f"""
    ã€ä»»åŠ¡ã€‘æ’°å†™ "Why School" éƒ¨åˆ†ã€‚
    ã€è¾“å…¥èƒŒæ™¯ã€‘
    - ç›®æ ‡å­¦æ ¡: {target_school_name}
    - é¡¾é—®æ€è·¯: {counselor_strategy}
    {f'ã€ç›®æ ‡è¯¾ç¨‹æ–‡æœ¬åˆ—è¡¨ã€‘:{target_curriculum_text}' if target_curriculum_text else ''}
    - è¯¾ç¨‹å›¾ç‰‡ä¿¡æ¯: è§é™„å¸¦å›¾ç‰‡
    ã€å†…å®¹è¦æ±‚ã€‘
    1. ç»¼åˆåˆ†ææä¾›çš„æ–‡æœ¬åˆ—è¡¨å’Œå›¾ç‰‡ä¸­çš„è¯¾ç¨‹ä¿¡æ¯ã€‚
    2. ä»ä¸­æŒ‘é€‰ 3-4 é—¨ä¸å­¦ç”ŸèƒŒæ™¯æˆ–è§„åˆ’æœ€ç›¸å…³çš„ç‰¹å®šè¯¾ç¨‹ã€‚
    3. è¯´æ˜è¿™äº›è¯¾ç¨‹ï¼ˆæåŠè¯¾åæˆ–æ¦‚å¿µï¼‰ä¸ºä½•å¸å¼•å­¦ç”ŸåŠæœ‰ä½•å¸®åŠ©ã€‚
    4. è¯­æ°”æœ´ç´ ä¸“ä¸šï¼Œè®®è®ºä¸ºä¸»ã€‚
    {CLEAN_OUTPUT_RULES}
    """

    prompt_internship = f"""
    ã€ä»»åŠ¡ã€‘æ’°å†™ "å®ä¹ /å·¥ä½œç»å†" (Professional Experience) éƒ¨åˆ†ã€‚
    ã€è¾“å…¥èƒŒæ™¯ã€‘
    - å­¦ç”Ÿç´ æ: è§é™„å¸¦æ–‡æœ¬
    - ç›®æ ‡ä¸“ä¸š: {target_school_name}
    ã€å†…å®¹è¦æ±‚ã€‘
    1. ç­›é€‰æœ€ç›¸å…³ç»å†ï¼ŒæŒ‰æ—¶é—´é¡ºåºé€»è¾‘ä¸²è”ã€‚
    2. ç»“æ„ï¼šèƒŒæ™¯ -> èŒè´£ -> æŠ€èƒ½ -> åŠ¨æœºã€‚
    3. æ‹’ç»æµæ°´è´¦ï¼Œè¦æœ‰é€»è¾‘æ¢³ç†å’Œåæ€ã€‚
    {CLEAN_OUTPUT_RULES}
    """

    prompts_map = {
        "Motivation": prompt_motivation,
        "Career_Goal": prompt_career,
        "Academic": prompt_academic,
        "Why_School": prompt_whyschool,
        "Internship": prompt_internship
    }

    for module in selected_modules:
        current_step += 1
        st.toast(f"æ­£åœ¨æ’°å†™: {modules[module]} ...")
        
        current_media = None
        if module == "Academic":
            current_media = transcript_content
        elif module == "Why_School":
            current_media = curriculum_imgs
        
        res = get_gemini_response(prompts_map[module], media_content=current_media, text_context=student_background_text)
        
        final_text = res.strip()
        
        if module == "Motivation":
            try:
                if "[TRENDS_START]" in res and "[DRAFT_START]" in res:
                    trends_part = res.split("[TRENDS_START]")[1].split("[TRENDS_END]")[0].strip()
                    draft_part = res.split("[DRAFT_START]")[1].split("[DRAFT_END]")[0].strip()
                    st.session_state['motivation_trends'] = trends_part
                    final_text = draft_part
                else:
                    final_text = res
            except:
                final_text = res

        st.session_state['generated_sections'][module] = final_text
        
        if f"text_{module}" in st.session_state:
            st.session_state[f"text_{module}"] = final_text
        
        if module in st.session_state['translated_sections']:
            del st.session_state['translated_sections'][module]
            
        progress_bar.progress(current_step / total_steps)

    st.success("åˆç¨¿ç”Ÿæˆå®Œæ¯•ï¼")

# ==========================================
# 8. ç•Œé¢ï¼šåé¦ˆã€ä¿®æ”¹ä¸ç¿»è¯‘ (äº¤äº’å‡çº§ + çµæ„ŸåŠ©æ‰‹)
# ==========================================
if st.session_state.get('generated_sections'):
    st.markdown("---")
    st.header("4. å®¡é˜…ã€ç²¾ä¿®ä¸ç¿»è¯‘")
    st.info("ğŸ‘‡ å·¦ä¾§ä¸ºä¸­æ–‡åˆç¨¿ï¼Œæ”¯æŒã€å±€éƒ¨ç²¾ä¿®ã€‘ï¼›å³ä¾§å¯é€‰ã€è‹±æ–‡ç¿»è¯‘ã€‘æˆ–ã€çµæ„ŸåŠ©æ‰‹ã€‘ã€‚")

    display_order = ["Motivation", "Academic", "Internship", "Why_School", "Career_Goal"]
    
    for module in display_order:
        if module in st.session_state['generated_sections']:
            with st.container():
                st.subheader(f"{modules[module]}")
                
                if module == "Motivation" and st.session_state.get('motivation_trends'):
                    with st.expander("ğŸ“š ç‚¹å‡»æŸ¥çœ‹ï¼šè¡Œä¸šè¶‹åŠ¿è°ƒç ”ä¸å‚è€ƒæº (Reference)", expanded=True):
                        st.info(st.session_state['motivation_trends'])
                
                c1, c2 = st.columns([1, 1])
                
                # --- å·¦ä¾§ï¼šä¸­æ–‡ç¼–è¾‘ä¸ç²¾ä¿® ---
                with c1:
                    st.markdown("**ä¸­æ–‡è‰ç¨¿ (å¯ç¼–è¾‘)**")
                    
                    if f"text_{module}" not in st.session_state:
                        st.session_state[f"text_{module}"] = st.session_state['generated_sections'][module]
                    
                    current_content = st.text_area(
                        f"ä¸­æ–‡å†…å®¹ - {module}", 
                        key=f"text_{module}",
                        height=350
                    )
                    st.session_state['generated_sections'][module] = current_content

                    # --- å±€éƒ¨ç²¾ä¿®é¢æ¿ ---
                    with st.expander("ğŸ› ï¸ ä¿®æ”¹å·¥å…·ç®±", expanded=False):
                        tab_global, tab_local = st.tabs(["å…¨å±€é‡å†™", "ğŸ” å±€éƒ¨/ç»†èŠ‚ç²¾ä¿®"])
                        
                        with tab_global:
                            fb_global = st.text_input(f"æ•´ä½“ä¿®æ”¹æ„è§", key=f"fb_glob_{module}")
                            if st.button("ğŸ”„ å…¨å±€é‡å†™", key=f"btn_glob_{module}"):
                                if not fb_global:
                                    st.warning("è¯·è¾“å…¥ä¿®æ”¹æ„è§")
                                else:
                                    with st.spinner("æ­£åœ¨å…¨å±€é‡å†™..."):
                                        revise_prompt = f"""
                                        ã€ä»»åŠ¡ã€‘æ ¹æ®åé¦ˆé‡å†™æ•´æ®µå†…å®¹ã€‚
                                        ã€åŸæ®µè½ã€‘{current_content}
                                        ã€ç”¨æˆ·åé¦ˆã€‘{fb_global}
                                        {CLEAN_OUTPUT_RULES}
                                        """
                                        revised_text = get_gemini_response(revise_prompt)
                                        st.session_state[f"text_{module}"] = revised_text.strip()
                                        st.session_state['generated_sections'][module] = revised_text.strip()
                                        if module in st.session_state['translated_sections']:
                                            del st.session_state['translated_sections'][module]
                                        st.rerun()

                        with tab_local:
                            st.caption("å¤åˆ¶ä¸Šæ–¹ä½ æƒ³æ”¹çš„é‚£å¥è¯ï¼Œç²˜è´´åˆ°ä¸‹æ–¹ï¼Œç„¶åå†™è¦æ±‚ã€‚")
                            col_target_text, col_instruction = st.columns(2)
                            with col_target_text:
                                target_segment = st.text_input("ğŸ¯ ç²˜è´´åŸæ–‡ç‰‡æ®µ", key=f"target_{module}")
                            with col_instruction:
                                local_instruction = st.text_input("âœï¸ æ€ä¹ˆæ”¹ï¼Ÿ", key=f"instr_{module}")
                            
                            if st.button("âœ¨ ä»…ä¿®æ”¹é€‰ä¸­éƒ¨åˆ†", key=f"btn_loc_{module}"):
                                if not target_segment or not local_instruction:
                                    st.warning("è¯·å¡«å†™åŸæ–‡ç‰‡æ®µå’Œä¿®æ”¹æ„è§")
                                else:
                                    with st.spinner("æ­£åœ¨è¿›è¡Œå±€éƒ¨ç²¾ä¿®..."):
                                        partial_revise_prompt = f"""
                                        ã€ä»»åŠ¡ã€‘å¯¹æ–‡ä¹¦æ®µè½è¿›è¡Œå±€éƒ¨ç²¾ä¿®ã€‚
                                        ã€å®Œæ•´åŸæ–‡ã€‘{current_content}
                                        ã€ç”¨æˆ·é”å®šçš„åŸæ–‡ç‰‡æ®µã€‘"{target_segment}"
                                        ã€ç”¨æˆ·çš„ä¿®æ”¹æ‰¹æ³¨ã€‘"{local_instruction}"
                                        ã€æ‰§è¡Œæ­¥éª¤ã€‘
                                        1. åœ¨å®Œæ•´åŸæ–‡ä¸­å®šä½è¯¥ç‰‡æ®µã€‚
                                        2. ä»…é’ˆå¯¹è¯¥ç‰‡æ®µåº”ç”¨ç”¨æˆ·çš„ä¿®æ”¹æ„è§ã€‚
                                        3. ä¿æŒæ®µè½å…¶ä»–éƒ¨åˆ†ä¸å˜ã€‚
                                        4. è¾“å‡ºä¿®æ”¹åçš„å®Œæ•´æ®µè½ã€‚
                                        {CLEAN_OUTPUT_RULES}
                                        """
                                        revised_text = get_gemini_response(partial_revise_prompt)
                                        st.session_state[f"text_{module}"] = revised_text.strip()
                                        st.session_state['generated_sections'][module] = revised_text.strip()
                                        if module in st.session_state['translated_sections']:
                                            del st.session_state['translated_sections'][module]
                                        st.rerun()

                # --- å³ä¾§ï¼šç¿»è¯‘ ä¸ çµæ„ŸåŠ©æ‰‹ (Tabs) ---
                with c2:
                    tab_trans, tab_chat = st.tabs(["ğŸ‡ºğŸ‡¸ è‹±æ–‡ç¿»è¯‘", "ğŸ¤– çµæ„ŸåŠ©æ‰‹ (Chat)"])
                    
                    # Tab 1: ç¿»è¯‘
                    with tab_trans:
                        st.markdown("**è‹±æ–‡ç¿»è¯‘ç»“æœ**")
                        if st.button(f"ğŸš€ ç¿»è¯‘æ­¤æ®µ", key=f"trans_btn_{module}"):
                            if not api_key:
                                st.error("éœ€è¦ API Key")
                            else:
                                with st.spinner("Translating..."):
                                    # --- åŠ¨æ€æ³¨å…¥æ‹¼å†™è§„åˆ™ ---
                                    spelling_instruction = ""
                                    if "British" in spelling_preference:
                                        spelling_instruction = "\nã€SPELLING RULEã€‘: STRICTLY use British English spelling (e.g., colour, analyse, programme, centre, organisation)."
                                    else:
                                        spelling_instruction = "\nã€SPELLING RULEã€‘: STRICTLY use American English spelling (e.g., color, analyze, program, center, organization)."
                                    
                                    content_to_translate = st.session_state[f"text_{module}"]
                                    
                                    # ç»„åˆå®Œæ•´ Prompt
                                    full_trans_prompt = f"{TRANSLATION_RULES_BASE}\n{spelling_instruction}\nã€Input Textã€‘:\n{content_to_translate}"
                                    
                                    trans_res = get_gemini_response(full_trans_prompt)
                                    st.session_state['translated_sections'][module] = trans_res.strip()
                        
                        if module in st.session_state['translated_sections']:
                            st.markdown(st.session_state['translated_sections'][module])
                            st.caption("ğŸ’¡ æç¤ºï¼šå¦‚æœä¿®æ”¹äº†å·¦ä¾§ä¸­æ–‡ï¼Œè¯·é‡æ–°ç‚¹å‡»ç¿»è¯‘æŒ‰é’®ã€‚")
                        else:
                            st.info("ğŸ‘ˆ æ»¡æ„å·¦ä¾§ä¸­æ–‡ç¨¿åï¼Œç‚¹å‡»ä¸Šæ–¹æŒ‰é’®ç”Ÿæˆç¿»è¯‘ã€‚")

                    # Tab 2: çµæ„ŸåŠ©æ‰‹ (Chat)
                    with tab_chat:
                        st.caption("ğŸ¤” é‡åˆ°å¡é¡¿ï¼Ÿåœ¨è¿™é‡ŒæŸ¥èµ„æ–™ã€é—®åŒä¹‰è¯æˆ–å¯»æ‰¾çµæ„Ÿã€‚")
                        
                        if module not in st.session_state['chat_histories']:
                            st.session_state['chat_histories'][module] = []
                        
                        chat_container = st.container(height=250)
                        with chat_container:
                            for msg in st.session_state['chat_histories'][module]:
                                with st.chat_message(msg["role"]):
                                    st.markdown(msg["content"])
                        
                        user_query = st.text_input(f"å‘åŠ©æ‰‹æé—® ({modules[module]})", key=f"chat_in_{module}")
                        
                        if st.button("å‘é€", key=f"chat_send_{module}"):
                            if not user_query:
                                st.warning("è¯·è¾“å…¥é—®é¢˜")
                            elif not api_key:
                                st.error("éœ€è¦ API Key")
                            else:
                                st.session_state['chat_histories'][module].append({"role": "user", "content": user_query})
                                
                                # è·å–éšæœºæ–‡æ¡ˆ
                                loading_msg = get_random_loading_msg()
                                
                                # å¼ºåˆ¶ Spinner åŒ…è£¹ API è°ƒç”¨
                                with st.spinner(loading_msg):
                                    chat_prompt = f"""
                                    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç•™å­¦æ–‡ä¹¦åŠ©æ‰‹ã€‚ç”¨æˆ·æ­£åœ¨æ’°å†™ '{modules[module]}' éƒ¨åˆ†ã€‚
                                    ç”¨æˆ·çš„é—®é¢˜æ˜¯ï¼š{user_query}
                                    è¯·æä¾›ç®€çŸ­ã€ä¸“ä¸šä¸”æœ‰å¸®åŠ©çš„å›ç­”ã€‚
                                    """
                                    ai_reply = get_gemini_response(chat_prompt)
                                    
                                    st.session_state['chat_histories'][module].append({"role": "assistant", "content": ai_reply})
                                    st.rerun()

    # ==========================================
    # 9. å¯¼å‡º
    # ==========================================
    st.markdown("---")
    st.header("5. æœ€ç»ˆå¯¼å‡º")
    
    full_text = ""
    for module in display_order:
        if module in st.session_state.get('translated_sections', {}):
            full_text += f"--- {modules[module]} (English) ---\n"
            clean_en = st.session_state['translated_sections'][module].replace("**", "")
            full_text += clean_en + "\n\n"
        elif module in st.session_state['generated_sections']:
            full_text += f"--- {modules[module]} (ä¸­æ–‡è‰ç¨¿) ---\n"
            full_text += st.session_state['generated_sections'][module] + "\n\n"
            
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½æ–‡ä¹¦ (.txt)",
        data=full_text,
        file_name=f"PS_{target_school_name}_{current_version}.txt",
        mime="text/plain",
        type="primary"
    )
