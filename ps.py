import streamlit as st
import google.generativeai as genai
from PIL import Image
import docx
import PyPDF2
import io
import os
import time
import random
from datetime import datetime

# ==========================================
# 0. è‡ªåŠ¨ç‰ˆæœ¬å·ç”Ÿæˆé€»è¾‘
# ==========================================
def get_app_version():
    try:
        timestamp = os.path.getmtime(__file__)
        dt = datetime.fromtimestamp(timestamp)
        # æ ¼å¼ï¼šv13.15.æœˆæ—¥.æ—¶åˆ†
        build_ver = dt.strftime('%m%d.%H%M')
        return f"v13.15.{build_ver}", dt.strftime('%Y-%m-%d %H:%M:%S')
    except Exception:
        return "v13.15.Dev", "Unknown"

current_version, last_updated_time = get_app_version()

# ==========================================
# 1. é¡µé¢åŸºç¡€é…ç½® & CSS æ³¨å…¥
# ==========================================
st.set_page_config(page_title=f"ç•™å­¦æ–‡ä¹¦å·¥å…· {current_version}", layout="wide")

# --- CSS Hack: å¼ºåˆ¶ä¸‰åˆ—å¡ç‰‡ç­‰é«˜ ---
st.markdown("""
<style>
    /* è®© Column å®¹å™¨å˜ä¸º Flex å¸ƒå±€ */
    div[data-testid="column"] {
        display: flex;
        flex-direction: column;
    }
    
    /* è®©å¸¦è¾¹æ¡†çš„å®¹å™¨ (Card) è‡ªåŠ¨æ’‘æ»¡é«˜åº¦ */
    div[data-testid="stVerticalBlockBorderWrapper"] {
        flex-grow: 1;
        display: flex;
        flex-direction: column;
    }
    
    /* ç¡®ä¿å†…éƒ¨å†…å®¹å¸ƒå±€åˆç† */
    div[data-testid="stVerticalBlockBorderWrapper"] > div {
        flex-grow: 1;
    }
    
    /* å¾®è°ƒ Label æ ·å¼ï¼Œä½¿å…¶æ›´ç´§å‡‘ */
    .stMarkdown p {
        margin-bottom: 0px;
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ– Session State
if 'generated_sections' not in st.session_state:
    st.session_state['generated_sections'] = {}
if 'motivation_trends' not in st.session_state:
    st.session_state['motivation_trends'] = ""
if 'translated_sections' not in st.session_state:
    st.session_state['translated_sections'] = {}
if 'chat_histories' not in st.session_state:
    st.session_state['chat_histories'] = {} 

st.title(f"ç•™å­¦æ–‡ä¹¦è¾…åŠ©å†™ä½œå·¥å…· {current_version}")
st.markdown("---")

# ==========================================
# 2. ç³»ç»Ÿè®¾ç½®
# ==========================================
with st.sidebar:
    st.header("ç³»ç»Ÿè®¾ç½®")
    
    api_key = st.text_input("ğŸ”‘ è¯·è¾“å…¥ Google API Key", type="password", help="è¯·åœ¨ Google AI Studio ç”³è¯· Key")
    
    if not api_key:
        st.warning("âš ï¸ è¯·è¾“å…¥ Key")
    else:
        st.success("âœ… Key å·²å°±ç»ª")
    
    model_name = st.selectbox("é€‰æ‹©æ¨¡å‹", ["gemini-3-pro-preview"], index=0)
    
    st.markdown("---")
    st.markdown("### å…³äº")
    st.info(f"**å½“å‰ç‰ˆæœ¬:** {current_version}")
    st.caption(f"**æœ€åæ›´æ–°:** {last_updated_time}")
    st.caption("**Update:** æ ‡é¢˜å»å›¾æ ‡ + è¯¾ç¨‹è®¾ç½® UI ç»Ÿä¸€")

# ==========================================
# 3. æ ¸å¿ƒå‡½æ•°ä¸æ–‡æ¡ˆåº“
# ==========================================

# --- å¹½é»˜åŠ è½½æ–‡æ¡ˆåº“ ---
FUNNY_LOADING_MESSAGES = [
    "â˜•ï¸ æ­£åœ¨ç…®å’–å•¡ï¼Œé¡ºä¾¿æ€è€ƒä¸€ä¸‹äººç”Ÿ...",
    "ğŸ§  æ­£åœ¨å’Œ Google æ€»éƒ¨çš„æœåŠ¡å™¨è¿›è¡Œè„‘ç”µæ³¢å¯¹æ¥...",
    "ğŸš€ æ­£åœ¨ä»¥æ­¤ç”Ÿæœ€å¿«çš„é€Ÿåº¦ç¿»é˜…æ•´ä¸ªäº’è”ç½‘...",
    "ğŸ¢ åˆ«æ€¥ï¼ŒAI ä¹Ÿæ˜¯éœ€è¦å–˜å£æ°”çš„...",
    "ğŸ”¥ ä¸ºäº†è¿™ä¸ªé—®é¢˜ï¼Œæ˜¾å¡æ­£åœ¨å¾®å¾®å‘çƒ«...",
    "ğŸ§™â€â™‚ï¸ æ­£åœ¨å¬å”¤æ•°æ®é­”æ³•ï¼Œè¯·å‹¿æ‰“æ‰°...",
    "ğŸ§ æ­£åœ¨å‡è£…å¾ˆæ·±æ²‰åœ°æ€è€ƒ...",
    "ğŸ’¾ æ­£åœ¨ä»èµ›åšç©ºé—´çš„è§’è½é‡Œæ‰“ææ•°æ®...",
    "âœ¨ çµæ„Ÿæ­£åœ¨åŠ è½½ä¸­ï¼Œè¿›åº¦ 99%...",
    "ğŸ¤– æ­£åœ¨å­¦ä¹ å¦‚ä½•åƒäººç±»ä¸€æ ·è¯´è¯...",
    "ğŸ“š æ­£åœ¨å¿«é€Ÿé˜…è¯» 1000 æœ¬ç›¸å…³ä¹¦ç±...",
    "ğŸª æ­£åœ¨å‘å¤–æ˜Ÿæ–‡æ˜å‘é€æ±‚åŠ©ä¿¡å·...",
    "ğŸ• æ­£åœ¨åƒä¸€å£è™šæ‹ŸæŠ«è¨è¡¥å……èƒ½é‡...",
    "ğŸ» æ­£åœ¨ä¸ºæ‚¨æ¼”å¥ä¸€é¦–æ•°æ®äº¤å“æ›²...",
    "ğŸƒâ€â™‚ï¸ æ­£åœ¨æ•°æ®çš„æµ·æ´‹é‡Œç‹‚å¥”...",
    "ğŸ§© æ­£åœ¨æ‹¼å‡‘é€»è¾‘çš„ç¢ç‰‡...",
    "ğŸ”‹ æ­£åœ¨ç»™ç¥ç»å…ƒå……ç”µ...",
    "ğŸ“¡ æ­£åœ¨æ ¡å‡†å«æ˜Ÿä¿¡å·...",
    "ğŸ§¹ æ­£åœ¨æ¸…ç†æ€ç»´é‡Œçš„æ‚è‰...",
    "ğŸ² æ­£åœ¨æ·éª°å­å†³å®šç”¨å“ªä¸ªè¯ï¼ˆå¼€ç©ç¬‘çš„ï¼‰..."
]

def get_random_loading_msg():
    return random.choice(FUNNY_LOADING_MESSAGES)

def read_word_file(file):
    try:
        doc = docx.Document(file)
        full_text = []
        for para in doc.paragraphs:
            full_text.append(para.text)
        return '\n'.join(full_text)
    except Exception as e:
        return f"Error reading Word file: {e}"

def read_pdf_text(file):
    try:
        pdf_reader = PyPDF2.PdfReader(file)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() + "\n"
        return text
    except Exception as e:
        return f"Error reading PDF file: {e}"

def get_gemini_response(prompt, media_content=None, text_context=None):
    if not api_key:
        return "Error: è¯·å…ˆåœ¨å·¦ä¾§ä¾§è¾¹æ è¾“å…¥ API Key"
        
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel(model_name)
    
    content = []
    content.append(prompt)
    
    if text_context:
        content.append(f"\nã€å‚è€ƒæ–‡æ¡£/èƒŒæ™¯ä¿¡æ¯ (ç®€å†æˆ–ç´ æè¡¨)ã€‘:\n{text_context}")
    
    if media_content:
        if isinstance(media_content, list):
            content.extend(media_content)
        else:
            content.append(media_content)
        
    try:
        response = model.generate_content(content)
        return response.text
    except Exception as e:
        return f"Error: {str(e)}"

# ==========================================
# 4. ç•Œé¢ï¼šä¿¡æ¯é‡‡é›† (UI ä¼˜åŒ–ç‰ˆ)
# ==========================================
st.header("1. ä¿¡æ¯é‡‡é›†ä¸ç´ æä¸Šä¼ ")

col_student, col_counselor, col_target = st.columns(3)

# --- ç¬¬ä¸€æ ï¼šå­¦ç”Ÿæä¾›ä¿¡æ¯ (å»é™¤å›¾æ ‡) ---
with col_student:
    with st.container(border=True):
        st.markdown("### å­¦ç”Ÿæä¾›ä¿¡æ¯") # å·²å»é™¤ ğŸ§‘â€ğŸ“
        st.caption("ä¸Šä¼ ç®€å†ã€ç´ æè¡¨ä¸æˆç»©å•")
        
        uploaded_material = st.file_uploader("ğŸ“„ æ–‡ä¹¦ç´ æ/ç®€å† (Word/PDF)", type=['docx', 'pdf'])
        uploaded_transcript = st.file_uploader("ğŸ“ æˆç»©å• (æˆªå›¾/PDF)", type=['png', 'jpg', 'jpeg', 'pdf'])

# --- ç¬¬äºŒæ ï¼šé¡¾é—®æŒ‡å¯¼æ„è§ (å»é™¤å›¾æ ‡) ---
with col_counselor:
    with st.container(border=True):
        st.markdown("### é¡¾é—®æŒ‡å¯¼æ„è§") # å·²å»é™¤ ğŸ‘¨â€ğŸ«
        st.caption("è®¾å®šæ–‡ä¹¦çš„æ•´ä½“ç­–ç•¥ä¸è°ƒæ€§")
        
        counselor_strategy = st.text_area(
            "ğŸ’¡ å†™ä½œç­–ç•¥/äººè®¾å¼ºè°ƒ", 
            height=300, 
            placeholder="ä¾‹å¦‚ï¼š\n1. å¼ºè°ƒé‡åŒ–èƒŒæ™¯\n2. è§£é‡ŠGPAåŠ£åŠ¿\n3. çªå‡ºæŸæ®µå®ä¹ çš„é¢†å¯¼åŠ›..."
        )

# --- ç¬¬ä¸‰æ ï¼šç›®æ ‡ä¸“ä¸šä¿¡æ¯ (å»é™¤å›¾æ ‡ + è¯¾ç¨‹UIç»Ÿä¸€) ---
with col_target:
    with st.container(border=True):
        st.markdown("### ç›®æ ‡ä¸“ä¸šä¿¡æ¯") # å·²å»é™¤ ğŸ«
        st.caption("è¾“å…¥ç›®æ ‡å­¦æ ¡ä¸è¯¾ç¨‹è®¾ç½®")
        
        target_school_name = st.text_input("ğŸ›ï¸ ç›®æ ‡å­¦æ ¡ & ä¸“ä¸š", placeholder="ä¾‹å¦‚ï¼šUCL - MSc Business Analytics")
        
        # --- UI è°ƒæ•´ï¼šå­—ä½“ä¸ä¸Šæ–¹ Input Label ä¿æŒä¸€è‡´ï¼Œå¹¶æ·»åŠ å›¾æ ‡ ---
        st.markdown("**ğŸ“– è¯¾ç¨‹è®¾ç½® (Curriculum)**") 
        
        tab_text, tab_img = st.tabs(["æ–‡æœ¬ç²˜è´´", "å›¾ç‰‡ä¸Šä¼ "])
        
        with tab_text:
            target_curriculum_text = st.text_area("ç²˜è´´è¯¾ç¨‹åˆ—è¡¨", height=160, placeholder="Core Modules: ...", label_visibility="collapsed")
        
        with tab_img:
            uploaded_curriculum_images = st.file_uploader("ä¸Šä¼ è¯¾ç¨‹æˆªå›¾", type=['png', 'jpg', 'jpeg'], accept_multiple_files=True, label_visibility="collapsed")

# è¯»å–ç´ ææ–‡æœ¬
student_background_text = ""
if uploaded_material:
    if uploaded_material.name.endswith('.docx'):
        student_background_text = read_word_file(uploaded_material)
    elif uploaded_material.name.endswith('.pdf'):
        student_background_text = read_pdf_text(uploaded_material)

# ==========================================
# 5. ç•Œé¢ï¼šæ¨¡å—é€‰æ‹©
# ==========================================
st.markdown("---")
st.header("2. å†™ä½œæ¨¡å—é€‰æ‹©")

modules = {
    "Motivation": "ç”³è¯·åŠ¨æœº",
    "Academic": "æœ¬ç§‘å­¦ä¹ ç»å†",
    "Internship": "å®ä¹ /å·¥ä½œç»å†",
    "Why_School": "Why School",
    "Career_Goal": "èŒä¸šè§„åˆ’"
}

selected_modules = st.multiselect("é€‰æ‹©æ¨¡å—ï¼š", list(modules.keys()), format_func=lambda x: modules[x], default=list(modules.keys()))

# ==========================================
# 6. æ ¸å¿ƒé€»è¾‘ï¼šç”Ÿæˆ Prompt
# ==========================================
st.markdown("---")
st.header("3. ä¸€é”®ç‚¹å‡»åˆ›ä½œ")

CLEAN_OUTPUT_RULES = """
ã€ğŸš¨ ç»å¯¹è¾“å‡ºè§„åˆ™ã€‘
1. åªè¾“å‡ºæ­£æ–‡å†…å®¹æœ¬èº«ã€‚
2. ä¸¥ç¦åŒ…å«å¼€åœºç™½ã€ç»“å°¾è¯­æˆ–ç»“æ„è¯´æ˜ã€‚
3. ä¸¥ç¦ä½¿ç”¨ Markdown æ ¼å¼ï¼ˆå¦‚åŠ ç²—ã€åˆ—è¡¨ç¬¦å·ã€æ ‡é¢˜ç¬¦å·ï¼‰ã€‚
4. è¾“å‡ºå¿…é¡»æ˜¯çº¯æ–‡æœ¬ã€‚
5. å¿…é¡»å†™æˆä¸€ä¸ªå®Œæ•´çš„ã€è¿è´¯çš„ä¸­æ–‡è‡ªç„¶æ®µã€‚
"""

TRANSLATION_RULES = """
ã€Translation Taskã€‘
Translate the provided Chinese text into a professional, human-sounding Personal Statement paragraph.

ã€ğŸš¨ CRITICAL ANTI-AI STYLE GUIDEã€‘
1. **KILL THE "AI SENTENCE PATTERN"**: 
   - **ABSOLUTELY FORBIDDEN**: The pattern "I did X, **thereby/thus/enabling** me to do Y." 
   - **SOLUTION**: Split into two sentences or use active verbs.

2. **SEMICOLONS (;) FOR FLOW**:
   - **MANDATORY**: When a sentence is grammatically complete but the thought is not finished (and leads directly into the next point), use a **semicolon (;)** to connect them.
   - *Example*: "The model failed initially; this failure forced me to re-evaluate the parameters."

3. **ADVERB CONTROL (Nuanced)**:
   - **STRICTLY PROHIBITED**: Adverbs placed immediately before verbs or adjectives to intensify them (e.g., "deeply analyze", "perfectly align").
   - **ALLOWED**: "Robust" and "scalable" are permitted.

4. **VOCABULARY PURGE**: 
   - Avoid "delve into", "pivotal", "tapestry". Use precise, simple words.

ã€ğŸš« BANNED WORDS LIST (Strictly Prohibited)ã€‘
[Verbs]: delve into, uncover, reveal, recognize, master, refine, cultivate, address, bridge, spearhead, pioneer, align with, stems from, underscore, highlight
[Adjectives/Adverbs]: instrumental, pivotal, seamless, systematically, rigorously, profoundly, deeply, acutely, keenly, comprehensively, perfectly, meticulously
[Nouns]: paradigm, trajectory, aspirations, vision, landscape, tapestry, realm, foundation
[Connectors]: thereby, thus (when used with -ing), in turn
[Phrases]: "not only... but also", "Building on this", "rich tapestry", "testament to", "a wide array of"

ã€Formattingã€‘
1. Output as ONE single paragraph.
2. Output the ENTIRE text in **Bold**.
3. No Markdown headers.

ã€Input Textã€‘:
"""

if st.button("å¼€å§‹ç”Ÿæˆåˆç¨¿", type="primary"):
    if not api_key:
        st.error("âŒ è¯·å…ˆåœ¨å·¦ä¾§ä¾§è¾¹æ è¾“å…¥æœ‰æ•ˆçš„ Google API Key")
        st.stop()

    has_curriculum = target_curriculum_text or uploaded_curriculum_images
    
    if not uploaded_material or not uploaded_transcript or not has_curriculum:
        st.error("è¯·ç¡®ä¿ï¼šæ–‡ä¹¦ç´ æ/ç®€å†ã€æˆç»©å•ã€ç›®æ ‡è¯¾ç¨‹ä¿¡æ¯ å‡å·²æä¾›ã€‚")
        st.stop()
    
    # å‡†å¤‡åª’ä½“
    transcript_content = []
    if uploaded_transcript.type == "application/pdf":
        transcript_content.append({
            "mime_type": "application/pdf",
            "data": uploaded_transcript.getvalue()
        })
    else:
        transcript_content.append(Image.open(uploaded_transcript))

    curriculum_imgs = []
    if uploaded_curriculum_images:
        for img_file in uploaded_curriculum_images:
            curriculum_imgs.append(Image.open(img_file))
    
    progress_bar = st.progress(0)
    total_steps = len(selected_modules)
    current_step = 0

    # --- Prompt å®šä¹‰ ---
    prompt_motivation = f"""
    ã€ä»»åŠ¡ã€‘æ’°å†™ Personal Statement çš„ "ç”³è¯·åŠ¨æœº" éƒ¨åˆ†ã€‚
    ã€æ­¥éª¤ 1ï¼šæ·±åº¦è°ƒç ”ã€‘
    è¯·å…ˆåˆ†æ {target_school_name} æ‰€åœ¨é¢†åŸŸçš„æœ€æ–°è¡Œä¸šçƒ­ç‚¹æˆ–å­¦æœ¯è¶‹åŠ¿ï¼ˆåˆ—å‡º 2-3 ä¸ªï¼‰ã€‚
    **å¿…é¡»æä¾›å…·ä½“ä¿¡æ¯æº**ï¼š
    - å…·ä½“çš„è®ºæ–‡æ ‡é¢˜ (Title & Year)
    - çŸ¥åå’¨è¯¢æœºæ„æŠ¥å‘Šåç§° (å¦‚ McKinsey, Deloitte, Gartner)
    - æƒå¨ç§‘æŠ€/å•†ä¸šæ–°é—»æº (å¦‚ TechCrunch, Bloomberg, Nature)
    - ç®€è¿°è¯¥è¶‹åŠ¿ä¸å­¦ç”ŸèƒŒæ™¯çš„å…³è”ã€‚
    ã€æ­¥éª¤ 2ï¼šæ’°å†™æ­£æ–‡ã€‘
    åŸºäºä¸Šè¿°è¶‹åŠ¿å’Œå­¦ç”Ÿç´ æï¼Œæ’°å†™ä¸€æ®µä¸­æ–‡ç”³è¯·åŠ¨æœºã€‚
    é€»è¾‘ï¼šå­¦ç”Ÿè¿‡å¾€ç»å† -> è§‚å¯Ÿåˆ°çš„è¡Œä¸šç—›ç‚¹/è¶‹åŠ¿ -> äº§ç”Ÿæ·±é€ éœ€æ±‚ã€‚
    ã€ğŸš¨ ä¸¥æ ¼è¾“å‡ºæ ¼å¼ã€‘
    è¯·ä¸¥æ ¼æŒ‰ç…§ä¸‹æ–¹åˆ†éš”ç¬¦è¾“å‡ºï¼Œä¸è¦åŒ…å«å…¶ä»–å†…å®¹ï¼š
    [TRENDS_START]
    (åœ¨æ­¤å¤„åˆ—å‡ºè°ƒç ”çš„è¶‹åŠ¿å’Œå…·ä½“æ¥æºé“¾æ¥/æ ‡é¢˜)
    [TRENDS_END]
    [DRAFT_START]
    (åœ¨æ­¤å¤„æ’°å†™æ­£æ–‡æ®µè½ï¼Œçº¯æ–‡æœ¬ï¼Œæ— Markdown)
    [DRAFT_END]
    """

    prompt_career = f"""
    ã€ä»»åŠ¡ã€‘æ’°å†™ "èŒä¸šè§„åˆ’" (Career Goals) éƒ¨åˆ†ã€‚
    ã€è¾“å…¥èƒŒæ™¯ã€‘
    - ç›®æ ‡ä¸“ä¸š: {target_school_name}
    - é¡¾é—®æ€è·¯: {counselor_strategy}
    ã€å†…å®¹è¦æ±‚ã€‘
    1. è§„åˆ’ç¡•å£«æ¯•ä¸šåçš„è·¯å¾„ï¼ˆåº”å±Šç”Ÿè§†è§’ï¼‰ã€‚
    2. **å¿…é¡»åŒ…å«**ï¼šå…·ä½“çš„å…¬å¸åå­—ã€å…·ä½“çš„èŒä½åç§°ã€‚
    3. å°†å·¥ä½œå†…å®¹å’Œæœªæ¥ç»§ç»­å­¦ä¹ æ–¹å‘èåˆåœ¨ä¸€æ®µè¯ä¸­ã€‚
    {CLEAN_OUTPUT_RULES}
    """

    prompt_academic = f"""
    ã€ä»»åŠ¡ã€‘æ’°å†™ "æœ¬ç§‘å­¦ä¹ ç»å†" (Academic Background) éƒ¨åˆ†ã€‚
    ã€è¾“å…¥èƒŒæ™¯ã€‘
    - ç›®æ ‡ä¸“ä¸š: {target_school_name}
    - æ ¸å¿ƒä¾æ® (æˆç»©å•): è§é™„å¸¦æ–‡ä»¶ (PDFæˆ–å›¾ç‰‡)
    - è¾…åŠ©å‚è€ƒ (å­¦ç”Ÿç´ æ/ç®€å†): è§é™„å¸¦æ–‡æœ¬
    ã€æ ¸å¿ƒåŸåˆ™ï¼šæ·±åº¦ > æ•°é‡ã€‘
    ä¸è¦ç½—åˆ—è¯¾ç¨‹åã€‚åªç²¾é€‰ **2-3 é—¨** ä¸ç›®æ ‡ä¸“ä¸šæœ€å¼ºç›¸å…³çš„æ ¸å¿ƒè¯¾ç¨‹è¿›è¡Œæ·±åº¦æå†™ã€‚
    ã€å†…å®¹è¦æ±‚ - å¿…é¡»åŒ…å«ç»†èŠ‚ã€‘
    1. **æ ¸å¿ƒæ¦‚å¿µæ¤å…¥**ï¼šåœ¨æè¿°æ¯é—¨è¯¾æ—¶ï¼Œå¿…é¡»æåŠè¯¥è¯¾ç¨‹å…·ä½“çš„**æ ¸å¿ƒæ¦‚å¿µã€æ¨¡å‹ã€ç®—æ³•æˆ–ç†è®ºåç§°**ã€‚
    2. **å­¦æœ¯çœŸå®æ„Ÿ**ï¼šç»“åˆå­¦ç”Ÿç´ æï¼Œç®€è¿°æ˜¯å¦‚ä½•ç†è§£æˆ–åº”ç”¨è¿™äº›æ¦‚å¿µçš„ã€‚
    3. **é€»è¾‘å‡å**ï¼šè¯´æ˜è¿™äº›å…·ä½“çš„çŸ¥è¯†ç‚¹å¦‚ä½•ä¸ºä½ æ”»è¯» {target_school_name} æ‰“ä¸‹äº†åšå®çš„å­¦æœ¯åŸºç¡€ã€‚
    4. **ç¦æ­¢**ï¼šç¦æ­¢å†™æˆè¯¾ç¨‹æ¸…å•ï¼ˆListï¼‰ï¼Œå¿…é¡»æ˜¯è¿è´¯çš„å­¦æœ¯åæ€å™è¿°ã€‚
    {CLEAN_OUTPUT_RULES}
    """

    prompt_whyschool = f"""
    ã€ä»»åŠ¡ã€‘æ’°å†™ "Why School" éƒ¨åˆ†ã€‚
    ã€è¾“å…¥èƒŒæ™¯ã€‘
    - ç›®æ ‡å­¦æ ¡: {target_school_name}
    - é¡¾é—®æ€è·¯: {counselor_strategy}
    {f'ã€ç›®æ ‡è¯¾ç¨‹æ–‡æœ¬åˆ—è¡¨ã€‘:{target_curriculum_text}' if target_curriculum_text else ''}
    - è¯¾ç¨‹å›¾ç‰‡ä¿¡æ¯: è§é™„å¸¦å›¾ç‰‡
    ã€å†…å®¹è¦æ±‚ã€‘
    1. ç»¼åˆåˆ†ææä¾›çš„æ–‡æœ¬åˆ—è¡¨å’Œå›¾ç‰‡ä¸­çš„è¯¾ç¨‹ä¿¡æ¯ã€‚
    2. ä»ä¸­æŒ‘é€‰ 3-4 é—¨ä¸å­¦ç”ŸèƒŒæ™¯æˆ–è§„åˆ’æœ€ç›¸å…³çš„ç‰¹å®šè¯¾ç¨‹ã€‚
    3. è¯´æ˜è¿™äº›è¯¾ç¨‹ï¼ˆæåŠè¯¾åæˆ–æ¦‚å¿µï¼‰ä¸ºä½•å¸å¼•å­¦ç”ŸåŠæœ‰ä½•å¸®åŠ©ã€‚
    4. è¯­æ°”æœ´ç´ ä¸“ä¸šï¼Œè®®è®ºä¸ºä¸»ã€‚
    {CLEAN_OUTPUT_RULES}
    """

    prompt_internship = f"""
    ã€ä»»åŠ¡ã€‘æ’°å†™ "å®ä¹ /å·¥ä½œç»å†" (Professional Experience) éƒ¨åˆ†ã€‚
    ã€è¾“å…¥èƒŒæ™¯ã€‘
    - å­¦ç”Ÿç´ æ: è§é™„å¸¦æ–‡æœ¬
    - ç›®æ ‡ä¸“ä¸š: {target_school_name}
    ã€å†…å®¹è¦æ±‚ã€‘
    1. ç­›é€‰æœ€ç›¸å…³ç»å†ï¼ŒæŒ‰æ—¶é—´é¡ºåºé€»è¾‘ä¸²è”ã€‚
    2. ç»“æ„ï¼šèƒŒæ™¯ -> èŒè´£ -> æŠ€èƒ½ -> åŠ¨æœºã€‚
    3. æ‹’ç»æµæ°´è´¦ï¼Œè¦æœ‰é€»è¾‘æ¢³ç†å’Œåæ€ã€‚
    {CLEAN_OUTPUT_RULES}
    """

    prompts_map = {
        "Motivation": prompt_motivation,
        "Career_Goal": prompt_career,
        "Academic": prompt_academic,
        "Why_School": prompt_whyschool,
        "Internship": prompt_internship
    }

    for module in selected_modules:
        current_step += 1
        st.toast(f"æ­£åœ¨æ’°å†™: {modules[module]} ...")
        
        current_media = None
        if module == "Academic":
            current_media = transcript_content
        elif module == "Why_School":
            current_media = curriculum_imgs
        
        res = get_gemini_response(prompts_map[module], media_content=current_media, text_context=student_background_text)
        
        final_text = res.strip()
        
        if module == "Motivation":
            try:
                if "[TRENDS_START]" in res and "[DRAFT_START]" in res:
                    trends_part = res.split("[TRENDS_START]")[1].split("[TRENDS_END]")[0].strip()
                    draft_part = res.split("[DRAFT_START]")[1].split("[DRAFT_END]")[0].strip()
                    st.session_state['motivation_trends'] = trends_part
                    final_text = draft_part
                else:
                    final_text = res
            except:
                final_text = res

        st.session_state['generated_sections'][module] = final_text
        
        if f"text_{module}" in st.session_state:
            st.session_state[f"text_{module}"] = final_text
        
        if module in st.session_state['translated_sections']:
            del st.session_state['translated_sections'][module]
            
        progress_bar.progress(current_step / total_steps)

    st.success("åˆç¨¿ç”Ÿæˆå®Œæ¯•ï¼")

# ==========================================
# 7. ç•Œé¢ï¼šåé¦ˆã€ä¿®æ”¹ä¸ç¿»è¯‘ (äº¤äº’å‡çº§ + çµæ„ŸåŠ©æ‰‹)
# ==========================================
if st.session_state.get('generated_sections'):
    st.markdown("---")
    st.header("4. å®¡é˜…ã€ç²¾ä¿®ä¸ç¿»è¯‘")
    st.info("ğŸ‘‡ å·¦ä¾§ä¸ºä¸­æ–‡åˆç¨¿ï¼Œæ”¯æŒã€å±€éƒ¨ç²¾ä¿®ã€‘ï¼›å³ä¾§å¯é€‰ã€è‹±æ–‡ç¿»è¯‘ã€‘æˆ–ã€çµæ„ŸåŠ©æ‰‹ã€‘ã€‚")

    display_order = ["Motivation", "Academic", "Internship", "Why_School", "Career_Goal"]
    
    for module in display_order:
        if module in st.session_state['generated_sections']:
            with st.container():
                st.subheader(f"{modules[module]}")
                
                if module == "Motivation" and st.session_state.get('motivation_trends'):
                    with st.expander("ğŸ“š ç‚¹å‡»æŸ¥çœ‹ï¼šè¡Œä¸šè¶‹åŠ¿è°ƒç ”ä¸å‚è€ƒæº (Reference)", expanded=True):
                        st.info(st.session_state['motivation_trends'])
                
                c1, c2 = st.columns([1, 1])
                
                # --- å·¦ä¾§ï¼šä¸­æ–‡ç¼–è¾‘ä¸ç²¾ä¿® ---
                with c1:
                    st.markdown("**ä¸­æ–‡è‰ç¨¿ (å¯ç¼–è¾‘)**")
                    
                    if f"text_{module}" not in st.session_state:
                        st.session_state[f"text_{module}"] = st.session_state['generated_sections'][module]
                    
                    current_content = st.text_area(
                        f"ä¸­æ–‡å†…å®¹ - {module}", 
                        key=f"text_{module}",
                        height=350
                    )
                    st.session_state['generated_sections'][module] = current_content

                    # --- å±€éƒ¨ç²¾ä¿®é¢æ¿ ---
                    with st.expander("ğŸ› ï¸ ä¿®æ”¹å·¥å…·ç®±", expanded=False):
                        tab_global, tab_local = st.tabs(["å…¨å±€é‡å†™", "ğŸ” å±€éƒ¨/ç»†èŠ‚ç²¾ä¿®"])
                        
                        with tab_global:
                            fb_global = st.text_input(f"æ•´ä½“ä¿®æ”¹æ„è§", key=f"fb_glob_{module}")
                            if st.button("ğŸ”„ å…¨å±€é‡å†™", key=f"btn_glob_{module}"):
                                if not fb_global:
                                    st.warning("è¯·è¾“å…¥ä¿®æ”¹æ„è§")
                                else:
                                    with st.spinner("æ­£åœ¨å…¨å±€é‡å†™..."):
                                        revise_prompt = f"""
                                        ã€ä»»åŠ¡ã€‘æ ¹æ®åé¦ˆé‡å†™æ•´æ®µå†…å®¹ã€‚
                                        ã€åŸæ®µè½ã€‘{current_content}
                                        ã€ç”¨æˆ·åé¦ˆã€‘{fb_global}
                                        {CLEAN_OUTPUT_RULES}
                                        """
                                        revised_text = get_gemini_response(revise_prompt)
                                        st.session_state[f"text_{module}"] = revised_text.strip()
                                        st.session_state['generated_sections'][module] = revised_text.strip()
                                        if module in st.session_state['translated_sections']:
                                            del st.session_state['translated_sections'][module]
                                        st.rerun()

                        with tab_local:
                            st.caption("å¤åˆ¶ä¸Šæ–¹ä½ æƒ³æ”¹çš„é‚£å¥è¯ï¼Œç²˜è´´åˆ°ä¸‹æ–¹ï¼Œç„¶åå†™è¦æ±‚ã€‚")
                            col_target_text, col_instruction = st.columns(2)
                            with col_target_text:
                                target_segment = st.text_input("ğŸ¯ ç²˜è´´åŸæ–‡ç‰‡æ®µ", key=f"target_{module}")
                            with col_instruction:
                                local_instruction = st.text_input("âœï¸ æ€ä¹ˆæ”¹ï¼Ÿ", key=f"instr_{module}")
                            
                            if st.button("âœ¨ ä»…ä¿®æ”¹é€‰ä¸­éƒ¨åˆ†", key=f"btn_loc_{module}"):
                                if not target_segment or not local_instruction:
                                    st.warning("è¯·å¡«å†™åŸæ–‡ç‰‡æ®µå’Œä¿®æ”¹æ„è§")
                                else:
                                    with st.spinner("æ­£åœ¨è¿›è¡Œå±€éƒ¨ç²¾ä¿®..."):
                                        partial_revise_prompt = f"""
                                        ã€ä»»åŠ¡ã€‘å¯¹æ–‡ä¹¦æ®µè½è¿›è¡Œå±€éƒ¨ç²¾ä¿®ã€‚
                                        ã€å®Œæ•´åŸæ–‡ã€‘{current_content}
                                        ã€ç”¨æˆ·é”å®šçš„åŸæ–‡ç‰‡æ®µã€‘"{target_segment}"
                                        ã€ç”¨æˆ·çš„ä¿®æ”¹æ‰¹æ³¨ã€‘"{local_instruction}"
                                        ã€æ‰§è¡Œæ­¥éª¤ã€‘
                                        1. åœ¨å®Œæ•´åŸæ–‡ä¸­å®šä½è¯¥ç‰‡æ®µã€‚
                                        2. ä»…é’ˆå¯¹è¯¥ç‰‡æ®µåº”ç”¨ç”¨æˆ·çš„ä¿®æ”¹æ„è§ã€‚
                                        3. ä¿æŒæ®µè½å…¶ä»–éƒ¨åˆ†ä¸å˜ã€‚
                                        4. è¾“å‡ºä¿®æ”¹åçš„å®Œæ•´æ®µè½ã€‚
                                        {CLEAN_OUTPUT_RULES}
                                        """
                                        revised_text = get_gemini_response(partial_revise_prompt)
                                        st.session_state[f"text_{module}"] = revised_text.strip()
                                        st.session_state['generated_sections'][module] = revised_text.strip()
                                        if module in st.session_state['translated_sections']:
                                            del st.session_state['translated_sections'][module]
                                        st.rerun()

                # --- å³ä¾§ï¼šç¿»è¯‘ ä¸ çµæ„ŸåŠ©æ‰‹ (Tabs) ---
                with c2:
                    tab_trans, tab_chat = st.tabs(["ğŸ‡ºğŸ‡¸ è‹±æ–‡ç¿»è¯‘", "ğŸ¤– çµæ„ŸåŠ©æ‰‹ (Chat)"])
                    
                    # Tab 1: ç¿»è¯‘
                    with tab_trans:
                        st.markdown("**è‹±æ–‡ç¿»è¯‘ç»“æœ**")
                        if st.button(f"ğŸš€ ç¿»è¯‘æ­¤æ®µ", key=f"trans_btn_{module}"):
                            if not api_key:
                                st.error("éœ€è¦ API Key")
                            else:
                                with st.spinner("Translating..."):
                                    content_to_translate = st.session_state[f"text_{module}"]
                                    full_trans_prompt = f"{TRANSLATION_RULES}\n{content_to_translate}"
                                    trans_res = get_gemini_response(full_trans_prompt)
                                    st.session_state['translated_sections'][module] = trans_res.strip()
                        
                        if module in st.session_state['translated_sections']:
                            st.markdown(st.session_state['translated_sections'][module])
                            st.caption("ğŸ’¡ æç¤ºï¼šå¦‚æœä¿®æ”¹äº†å·¦ä¾§ä¸­æ–‡ï¼Œè¯·é‡æ–°ç‚¹å‡»ç¿»è¯‘æŒ‰é’®ã€‚")
                        else:
                            st.info("ğŸ‘ˆ æ»¡æ„å·¦ä¾§ä¸­æ–‡ç¨¿åï¼Œç‚¹å‡»ä¸Šæ–¹æŒ‰é’®ç”Ÿæˆç¿»è¯‘ã€‚")

                    # Tab 2: çµæ„ŸåŠ©æ‰‹ (Chat)
                    with tab_chat:
                        st.caption("ğŸ¤” é‡åˆ°å¡é¡¿ï¼Ÿåœ¨è¿™é‡ŒæŸ¥èµ„æ–™ã€é—®åŒä¹‰è¯æˆ–å¯»æ‰¾çµæ„Ÿã€‚")
                        
                        if module not in st.session_state['chat_histories']:
                            st.session_state['chat_histories'][module] = []
                        
                        chat_container = st.container(height=250)
                        with chat_container:
                            for msg in st.session_state['chat_histories'][module]:
                                with st.chat_message(msg["role"]):
                                    st.markdown(msg["content"])
                        
                        user_query = st.text_input(f"å‘åŠ©æ‰‹æé—® ({modules[module]})", key=f"chat_in_{module}")
                        
                        if st.button("å‘é€", key=f"chat_send_{module}"):
                            if not user_query:
                                st.warning("è¯·è¾“å…¥é—®é¢˜")
                            elif not api_key:
                                st.error("éœ€è¦ API Key")
                            else:
                                st.session_state['chat_histories'][module].append({"role": "user", "content": user_query})
                                
                                # è·å–éšæœºæ–‡æ¡ˆ
                                loading_msg = get_random_loading_msg()
                                
                                # å¼ºåˆ¶ Spinner åŒ…è£¹ API è°ƒç”¨
                                with st.spinner(loading_msg):
                                    chat_prompt = f"""
                                    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç•™å­¦æ–‡ä¹¦åŠ©æ‰‹ã€‚ç”¨æˆ·æ­£åœ¨æ’°å†™ '{modules[module]}' éƒ¨åˆ†ã€‚
                                    ç”¨æˆ·çš„é—®é¢˜æ˜¯ï¼š{user_query}
                                    è¯·æä¾›ç®€çŸ­ã€ä¸“ä¸šä¸”æœ‰å¸®åŠ©çš„å›ç­”ã€‚
                                    """
                                    ai_reply = get_gemini_response(chat_prompt)
                                    
                                    st.session_state['chat_histories'][module].append({"role": "assistant", "content": ai_reply})
                                    st.rerun()

    # ==========================================
    # 8. å¯¼å‡º
    # ==========================================
    st.markdown("---")
    st.header("5. æœ€ç»ˆå¯¼å‡º")
    
    full_text = ""
    for module in display_order:
        if module in st.session_state.get('translated_sections', {}):
            full_text += f"--- {modules[module]} (English) ---\n"
            clean_en = st.session_state['translated_sections'][module].replace("**", "")
            full_text += clean_en + "\n\n"
        elif module in st.session_state['generated_sections']:
            full_text += f"--- {modules[module]} (ä¸­æ–‡è‰ç¨¿) ---\n"
            full_text += st.session_state['generated_sections'][module] + "\n\n"
            
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½æ–‡ä¹¦ (.txt)",
        data=full_text,
        file_name=f"PS_{target_school_name}_{current_version}.txt",
        mime="text/plain",
        type="primary"
    )
